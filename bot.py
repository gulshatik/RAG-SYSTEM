import os
import re
import json
from docx import Document
import chromadb
from chromadb.utils import embedding_functions
import hashlib
import win32com.client
from openai import OpenAI
import time
import logging
import traceback
import sys
from docx.shared import Pt
import PyPDF2
import textwrap
from collections import deque
from vector_rag_db import VectorRAGDatabase
from telegram import Update, ReplyKeyboardMarkup, ReplyKeyboardRemove
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    filters,
    ContextTypes,
    ConversationHandler
)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("app.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)
logger.info("–õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π UTF-8")
POSITION, DEPARTMENT = range(2)
DOCUMENTS_DIR = r"–ü–û–õ–ù–´–ô –ü–£–¢–¨ –ö –ü–ê–ü–ö–ï –° –ì–û–¢–û–í–´–ú–ò –î–û–õ–ñ–ù–û–°–¢–ù–´–ú–ò –ò–ù–°–¢–†–£–ö–¶–ò–Ø–ú–ò"
VECTOR_DB_PATH = r"–ü–û–õ–ù–´–ô –ü–£–¢–¨ –ö –ü–ê–ü–ö–ï –ì–î–ï –ë–£–î–ï–¢ –•–†–ê–ù–ò–¢–¨–°–Ø –í–ï–ö–¢–û–†–ù–ê–Ø –ë–ê–ó–ê –î–ê–ù–ù–´–•"
OUTPUT_DIR = r"–ü–û–õ–ù–´–ô –ü–£–¢–¨ –ö –ü–ê–ü–ö–ï –ì–î–ï –ë–£–î–£–¢ –•–†–ê–ù–ò–¢–¨–°–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–´"
TEMPLATE_PATH = r"–ü–û–õ–ù–´–ô –ü–£–¢–¨ –ö –î–û–ö–£–ú–ï–ù–¢–£ –®–∞–±–ª–æ–Ω.docx"
TOKEN = "–¢–û–ö–ï–ù –¢–ï–õ–ï–ì–†–ê–ú –ë–û–¢–ê"

LAST_API_REQUEST_TIME = 0
vector_db = None
deepseek_client = None

def init_system():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
    global vector_db, deepseek_client
    
    deepseek_client = OpenAI(
        base_url="–°–°–´–õ–ö–ê SCALEWAY",
        api_key="API –ö–õ–Æ–ß"
    )
    
    vector_db = VectorRAGDatabase(DOCUMENTS_DIR, VECTOR_DB_PATH)
    logger.info("–°–∏—Å—Ç–µ–º–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """–ù–∞—á–∞–ª–æ –¥–∏–∞–ª–æ–≥–∞"""
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–æ–ª–∂–Ω–æ—Å—Ç–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π.\n"
        "–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏:",
        reply_markup=ReplyKeyboardRemove()
    )
    return POSITION

async def get_position(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–æ–ª–∂–Ω–æ—Å—Ç–∏"""
    context.user_data['position'] = update.message.text
    await update.message.reply_text("–¢–µ–ø–µ—Ä—å –≤–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è:")
    return DEPARTMENT

async def get_department(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∏ –∑–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
    context.user_data['department'] = update.message.text
    position = context.user_data['position']
    department = context.user_data['department']
    
    await update.message.reply_text(
        f"–ù–∞—á–∏–Ω–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è:\n"
        f"–î–æ–ª–∂–Ω–æ—Å—Ç—å: {position}\n"
        f"–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ: {department}\n"
        "–≠—Ç–æ –∑–∞–π–º–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç..."
    )
    try:
        output_path = generate_job_description(position, department)
        with open(output_path, 'rb') as doc_file:
            await update.message.reply_document(
                document=doc_file,
                caption=f"–î–æ–ª–∂–Ω–æ—Å—Ç–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è {position}"
            )
        os.remove(output_path)  
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}")
        await update.message.reply_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ üò¢")
    
    return ConversationHandler.END

async def cancel(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """–û—Ç–º–µ–Ω–∞ –¥–∏–∞–ª–æ–≥–∞"""
    await update.message.reply_text(
        "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞",
        reply_markup=ReplyKeyboardRemove()
    )
    return ConversationHandler.END

def generate_job_description(position: str, department: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –≤–∞—à–µ–π main)"""
    global LAST_API_REQUEST_TIME
    
    template_doc = Document(TEMPLATE_PATH)
    if not template_doc:
        raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —à–∞–±–ª–æ–Ω")
    
    processed_doc = process_template(template_doc, position, department)
    if not processed_doc:
        raise Exception("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —à–∞–±–ª–æ–Ω–∞")
    
    output_filename = f"–î–ò_{position}_{time.strftime('%Y%m%d_%H%M%S')}.docx"
    output_path = os.path.join(OUTPUT_DIR, output_filename)
    
    if not save_document(processed_doc, output_path):
        raise Exception("–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞")
    
    return output_path

def to_accusative_via_llm(phrase: str) -> str:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ñ—Ä–∞–∑—É –≤ —Ä–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞–¥–µ–∂ —Å –ø–æ–º–æ—â—å—é LLM"""
    global LAST_API_REQUEST_TIME
    try:
        logger.info(f"–ó–∞–ø—Ä–æ—Å –∫ LLM –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ —Ä–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞–¥–µ–∂: {phrase}")


        current_time = time.time()
        if LAST_API_REQUEST_TIME > 0:
            elapsed = current_time - LAST_API_REQUEST_TIME
            if elapsed < 60:  
                sleep_time = 60 - elapsed
                logger.info(f"–û–∂–∏–¥–∞–Ω–∏–µ {sleep_time:.2f} —Å–µ–∫ –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º...")
                time.sleep(sleep_time)
        
        LAST_API_REQUEST_TIME = time.time()

        prompt = (
            "<think>\n"
            f"–ü—Ä–µ–æ–±—Ä–∞–∑—É—é –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏ '{phrase}' –≤ —Ä–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞–¥–µ–∂.\n"
            "–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–ª–∂–Ω–æ—Å—Ç–∏ –∏ –ø—Ä–∏–º–µ–Ω—è—é –ø—Ä–∞–≤–∏–ª–∞ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞.\n"
            "–û–ø—Ä–µ–¥–µ–ª—è—é –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ –≤ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏.\n"
            "</think>\n"
            f"—Ä–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞–¥–µ–∂: "
        )
        
        response = deepseek_client.chat.completions.create(
            model="deepseek-r1-distill-llama-70b",
            messages=[
                {
                    "role": "system", 
                    "content": (
                        "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä—É—Å—Å–∫–æ–º—É —è–∑—ã–∫—É. –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π —Ñ–æ—Ä–º–∞—Ç —Å —Ç–µ–≥–∞–º–∏ <think> –¥–ª—è —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π. "
                        "–∏ –ø–æ—Å–ª–µ —Ç–µ–≥–∞ </think> –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–π —Ç–æ–ª—å–∫–æ –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç - –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏. "
                        "–ò—Å–ø–æ–ª—å–∑—É–π –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä –∏ –Ω–µ –¥–æ–±–∞–≤–ª—è–π –Ω–∏–∫–∞–∫–∏—Ö –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤ –∏–ª–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.–æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ </think> '–æ—Ç–≤–µ—Ç' <end>"
                    )
                },
                {"role": "user", "content": prompt}
            ],
            max_tokens=50,
            temperature=0.0,
            stop=["<end>"] 
        )
        
        result = response.choices[0].message.content.strip()
        
        if "</think>" in result:
            generated_text = result.split("</think>")[-1].strip()
            
            prefixes = ["—Ä–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞–¥–µ–∂:", "–û—Ç–≤–µ—Ç:", "–†–µ–∑—É–ª—å—Ç–∞—Ç:", "'–æ—Ç–≤–µ—Ç'", "‚Ä¢", "-", "'"]
            for prefix in prefixes:
                if generated_text.startswith(prefix):
                    generated_text = generated_text[len(prefix):].strip()
            
            if generated_text.startswith('"') and generated_text.endswith('"'):
                generated_text = generated_text[1:-1].strip()
            elif generated_text.startswith("'") and generated_text.endswith("'"):
                generated_text = generated_text[1:-1].strip()
                
            logger.info(f"–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ –≤ —Ä–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞–¥–µ–∂: {phrase} -> {generated_text}")
            return generated_text
        else:
            clean_result = re.sub(r'</?[a-z]+>', '', result, flags=re.IGNORECASE)
            logger.info(f"–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ –±–µ–∑ —Ç–µ–≥–∞: {phrase} -> {clean_result}")
            return clean_result
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ —Ä–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞–¥–µ–∂: {str(e)}")
        return phrase 

PLACEHOLDER_CONFIG = {
    "–û–ë–©–ò–ï –ü–û–õ–û–ñ–ï–ù–ò–Ø 1.2": {
        "prompt": "–°–æ—Å—Ç–∞–≤—å –ø—É–Ω–∫—Ç 1.2 '–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—é –∏ —Å—Ç–∞–∂—É —Ä–∞–±–æ—Ç—ã' —Ä–∞–∑–¥–µ–ª–∞ '–û–±—â–∏–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è' –¥–ª—è –¥–æ–ª–∂–Ω–æ—Å—Ç–∏ {position} –≤ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏ {department}. –ò—Å–ø–æ–ª—å–∑—É–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫. 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è",
        "context_query": "—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—é –∏ —Å—Ç–∞–∂—É —Ä–∞–±–æ—Ç—ã –¥–ª—è –¥–æ–ª–∂–Ω–æ—Å—Ç–∏ {position}"
    },
    "–û–ë–©–ò–ï –ü–û–õ–û–ñ–ï–ù–ò–Ø 1.3": {
        "prompt": "–°–æ—Å—Ç–∞–≤—å –ø—É–Ω–∫—Ç 1.3 —Ä–∞–∑–¥–µ–ª–∞ '–û–±—â–∏–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è' –¥–ª—è {position} ({department}). –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç '–õ–∏—Ü–æ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç—Å—è –Ω–∞ –¥–æ–ª–∂–Ω–æ—Å—Ç—å {position} –∏ –æ—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç—Å—è –æ—Ç –Ω–µ–µ –ø—Ä–∏–∫–∞–∑–æ–º —Ä–µ–∫—Ç–æ—Ä–∞ –ö–§–£ (–ø—Ä–æ—Ä–µ–∫—Ç–æ—Ä–∞, –∏–Ω–æ–≥–æ —É–ø–æ–ª–Ω–æ–º–æ—á–µ–Ω–Ω–æ–≥–æ —Ä–µ–∫—Ç–æ—Ä–æ–º –ª–∏—Ü–∞) –≤ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–º –¥–µ–π—Å—Ç–≤—É—é—â–∏–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏ –ø–æ—Ä—è–¥–∫–µ. {position} –ø–æ–¥—á–∏–Ω—è–µ—Ç—Å—è –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ (—Ç—É—Ç –Ω–∞–ø–∏—à–∏ '–≥–ª–∞–≤–µ {department}').' –±–æ–ª—å—à–µ –Ω–∏–∫–∞–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.",
        "context_query": "–ø–æ—Ä—è–¥–æ–∫ –ø—Ä–∏–µ–º–∞ –∏ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è –æ—Ç –¥–æ–ª–∂–Ω–æ—Å—Ç–∏ {position}"
    },
    "–û–ë–©–ò–ï –ü–û–õ–û–ñ–ï–ù–ò–Ø 1.4": {
        "prompt": "–ü–µ—Ä–µ—á–∏—Å–ª–∏ —á—Ç–æ –¥–æ–ª–∂–µ–Ω –∑–Ω–∞—Ç—å {position} ({department}). –§–æ—Ä–º–∞—Ç: - [—Ç–µ–∫—Å—Ç]. –û—Ç–≤–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–µ–∫—Å—Ç '- –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏—é –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏, –∏–Ω—ã–µ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã–µ –∏ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–∞–≤–æ–≤—ã–µ –∞–∫—Ç—ã, –º–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã, –æ–ø—Ä–µ–¥–µ–ª—è—é—â–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∞–∑–≤–∏—Ç–∏—è –≤—ã—Å—à–µ–≥–æ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏, –∞ —Ç–∞–∫–∂–µ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–∞–≤–æ–≤—ã–µ –∞–∫—Ç—ã, –º–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –ø–æ —Ç–µ–º–∞—Ç–∏–∫–µ —Ä–∞–±–æ—Ç—ã, –æ—Å–Ω–æ–≤—ã —Ç—Ä—É–¥–æ–≤–æ–≥–æ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ —Ç—Ä—É–¥–∞ –≤ –†–§;- –£—Å—Ç–∞–≤ –ö–§–£, –ü—Ä–∞–≤–∏–ª–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ —Ä–∞—Å–ø–æ—Ä—è–¥–∫–∞ –ö–§–£, –ü–æ–ª–æ–∂–µ–Ω–∏–µ –æ –ø—Ä–æ–ø—É—Å–∫–Ω–æ–º –∏ –≤–Ω—É—Ç—Ä–∏–æ–±—ä–µ–∫—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ –ö–§–£, –ö–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—ã–π –¥–æ–≥–æ–≤–æ—Ä –ö–§–£, –ü–æ–ª–æ–∂–µ–Ω–∏–µ –æ (–ø–æ–ª–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è), –ü–æ–ª–æ–∂–µ–Ω–∏–µ –æ (–ø–æ–ª–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏), –ö–æ–¥–µ–∫—Å —ç—Ç–∏–∫–∏ –∏ —Å–ª—É–∂–µ–±–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è —Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤ –ö–§–£ –∏ –∏–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –∞–∫—Ç—ã –ö–§–£;- —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Å–ø–µ—Ü–∏—Ñ–∏–∫—É –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ö–§–£;'–î–∞–ª–µ–µ –¥–æ–±–∞–≤—å 3-12 –ø—É–Ω–∫—Ç–æ–≤ (–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–æ–ª–∂–Ω–æ—Å—Ç–∏) –∫–∞–∫–∏–º–∏ –∑–Ω–∞–Ω–∏—è–º–∏ –¥–æ–ª–∂–µ–Ω –æ–±–ª–∞–¥–∞—Ç—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫. –ò—Å–ø–æ–ª—å–∑—É–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫, –Ω–∏–∫–∞–∫–æ–≥–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.",
        "context_query": "–∑–Ω–∞–Ω–∏—è –∏ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –¥–ª—è –¥–æ–ª–∂–Ω–æ—Å—Ç–∏ {position}"
    },
    "–î–û–õ–ñ–ù–û–°–¢–ù–´–ï –û–ë–Ø–ó–ê–ù–ù–û–°–¢–ò": {
        "prompt": "–ö–∞–∫–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–Ω—ã–µ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª–Ω—è–µ—Ç {position} ({department}). –§–æ—Ä–º–∞—Ç: - [—Ç–µ–∫—Å—Ç]. –õ—é–±–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—É–Ω–∫—Ç–æ–≤, –≤ –∫–∞–∂–¥–æ–º –ø—É–Ω–∫—Ç–µ –º–∞–∫—Å–∏–º—É–º 2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ò—Å–ø–æ–ª—å–∑—É–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫, –Ω–∏–∫–∞–∫–æ–≥–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.",
        "context_query": "–¥–æ–ª–∂–Ω–æ—Å—Ç–Ω—ã–µ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ {position}"
    }
}

def generate_placeholder_content(placeholder: str, context: dict) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAG"""
    global LAST_API_REQUEST_TIME
    try:
        logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–ª—è –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–∞: [{placeholder}]")
        
        if placeholder not in PLACEHOLDER_CONFIG:
            logger.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä: {placeholder}")
            return f"[{placeholder}]"
        
        config = PLACEHOLDER_CONFIG[placeholder]
        prompt_template = config["prompt"]
        context_query = config.get("context_query", "").format(**context)

        base_prompt = prompt_template.format(**context)

        logger.info(f"–ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {base_prompt[:200]}...")

        if context_query:
            relevant_chunks = vector_db.search_relevant_chunks(context_query, n_results=3)
            rag_context = "\n\n".join([f"–ò—Å—Ç–æ—á–Ω–∏–∫: {chunk['source']}\n–ö–æ–Ω—Ç–µ–Ω—Ç: {chunk['content']}" 
                                      for chunk in relevant_chunks])
            
            full_prompt = (
                "–ò—Å–ø–æ–ª—å–∑—É–π —Å–ª–µ–¥—É—é—â–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∏–∑ –¥–æ–ª–∂–Ω–æ—Å—Ç–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π "
                "–∏ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞:\n\n"
                f"{rag_context}\n\n"
                "–ó–∞–¥–∞–Ω–∏–µ:\n"
                f"{base_prompt}"
            )
        else:
            full_prompt = base_prompt
        
        logger.info(f"–ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {full_prompt[:500]}...")

        current_time = time.time()
        if LAST_API_REQUEST_TIME > 0:
            elapsed = current_time - LAST_API_REQUEST_TIME
            if elapsed < 60: 
                sleep_time = 60
                logger.info(f"–û–∂–∏–¥–∞–Ω–∏–µ {sleep_time:.2f} —Å–µ–∫ –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º...")
                time.sleep(sleep_time)
        
        LAST_API_REQUEST_TIME = time.time()

        response = deepseek_client.chat.completions.create(
            model="deepseek-r1-distill-llama-70b",
            messages=[
                {
                    "role": "system", 
                    "content": (
                        "–¢—ã HR-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç, —Å–æ—Å—Ç–∞–≤–ª—è—é—â–∏–π –¥–æ–ª–∂–Ω–æ—Å—Ç–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏. "
                        "–ò—Å–ø–æ–ª—å–∑—É–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –∏ —Ç–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫."
                    )
                },
                {"role": "user", "content": full_prompt}
            ],
            max_tokens=1500,
            temperature=0.3
        )
        
        result = response.choices[0].message.content.strip()
        if "</think>" in result:

            generated_text = result.split("</think>")[-1].strip()

            generated_text = re.sub(r'</?[a-z]+>', '', generated_text, flags=re.IGNORECASE)
            logger.info(f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç: {generated_text[:100]}...")
            return generated_text
        else:
            logger.info(f"–ö–æ–Ω—Ç–µ–Ω—Ç –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {result[:100]}...")
            return result
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}")
        logger.error(traceback.format_exc())
        return f"[{placeholder}]"          


def read_docx(file_path: str) -> Document:
    """–ß—Ç–µ–Ω–∏–µ .docx —Ñ–∞–π–ª–∞"""
    try:
        logger.info(f"–ß—Ç–µ–Ω–∏–µ .docx —Ñ–∞–π–ª–∞: {os.path.basename(file_path)}")
        return Document(file_path)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è DOCX: {str(e)}")
        return None

def process_template(template_doc: Document, position: str, department: str) -> Document:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —à–∞–±–ª–æ–Ω–∞ —Å –∑–∞–º–µ–Ω–æ–π –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤"""
    try:
        logger.info("–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —à–∞–±–ª–æ–Ω–∞...")
        

        context = {
            "position": position,
            "department": department
        }
        
        placeholder_pattern = re.compile(r"\[([^\]]+)\]")
        
        for paragraph in template_doc.paragraphs:
            if placeholder_pattern.search(paragraph.text):
                def replace_placeholder(match):
                    placeholder_name = match.group(1).strip()
                    
                    if "–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏" in placeholder_name.lower():
                        is_uppercase = placeholder_name[0].isupper()
                        return position if is_uppercase else to_accusative_via_llm(position)
                            
                    elif "–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–∞—Ñ–µ–¥—Ä—ã" in placeholder_name.lower():
                        return department
                    elif "–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è" in placeholder_name.lower():
                        return department
                    
                    return generate_placeholder_content(placeholder_name, context)
                
                paragraph.text = placeholder_pattern.sub(replace_placeholder, paragraph.text)
        
        logger.info("–®–∞–±–ª–æ–Ω —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
        return template_doc
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —à–∞–±–ª–æ–Ω–∞: {str(e)}")
        logger.error(traceback.format_exc())
        return None

def save_document(doc: Document, output_path: str) -> bool:
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    try:
        logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {output_path}")
        doc.save(output_path)
        return True
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}")
        return False


def main() -> None:
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    init_system()
    
    application = Application.builder().token(TOKEN).build()
    
    conv_handler = ConversationHandler(
        entry_points=[CommandHandler("start", start)],
        states={
            POSITION: [MessageHandler(filters.TEXT & ~filters.COMMAND, get_position)],
            DEPARTMENT: [MessageHandler(filters.TEXT & ~filters.COMMAND, get_department)],
        },
        fallbacks=[CommandHandler("cancel", cancel)],
    )
    
    application.add_handler(conv_handler)
    
    logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω")
    application.run_polling()

if __name__ == "__main__":
    main()
